# 11. Rust中的同步并发

并发（Concurrency）是“同时处理很多任务”的能力，并行（Parallelism）是“同一时刻真正同时运行”。
Rust 在并发上的核心目标不是“写起来最省事”，而是：

- 尽量把数据竞争（data race）这类 bug **在编译期消灭**
- 用类型系统把“共享”和“可变”这两件事组织得更可控

本章按两条路线讲清楚 Rust 的同步并发：

- **共享内存**：`Arc<Mutex<T>>` / `Arc<RwLock<T>>`
- **消息传递**：`std::sync::mpsc` 的 channel

并在中间穿插最关键但容易被忽略的部分：`Send` / `Sync`（自动 trait）以及原子类型。

---

## 11.1 线程模型：线程、并发、并行；创建与管理

### 11.1.1 线程是什么

线程（thread）可以理解为：操作系统调度的最小执行单元之一。一个进程里可以有多个线程，共享同一进程的地址空间（也就带来了共享数据的风险）。

在 Rust 里，标准库 `std::thread` 提供了原生线程 API。Rust 本身不会“自动并发”，你需要显式创建线程，或者使用 async（见第 12 章）。

### 11.1.2 并发 vs 并行

- **并发**：在同一段时间内推进多个任务（可以交替执行）。
- **并行**：在同一时刻多个任务真的同时执行（需要多核/多 CPU）。

一个常见的理解方式：

- 并发关注“结构”：把任务拆开，让系统能更好地利用等待时间（I/O 等）
- 并行关注“吞吐”：真的同时跑起来提升速度

### 11.1.3 创建线程：`thread::spawn`

`thread::spawn` 接收一个闭包并在新线程中执行，返回 `JoinHandle<T>`。

```rust
use std::thread;
use std::time::Duration;

fn main() {
	let handle = thread::spawn(|| {
		for i in 1..=3 {
			println!("worker: {i}");
			thread::sleep(Duration::from_millis(50));
		}
		42
	});

	for i in 1..=2 {
		println!("main: {i}");
		thread::sleep(Duration::from_millis(50));
	}

	let answer = handle.join().unwrap();
	println!("joined: {answer}");
}
```

几点注意：

- `spawn` 的闭包通常需要是 `'static`（因为线程可能比创建它的栈帧活得更久）
- `join()` 会阻塞等待线程结束；如果子线程 panic，`join()` 返回 `Err`

### 11.1.4 捕获变量：`move` 闭包与所有权转移

新线程里通常要用到主线程的变量，这就涉及所有权。

```rust
use std::thread;

fn main() {
	let v = vec![1, 2, 3];

	let handle = thread::spawn(move || {
		// move 把 v 的所有权转移进线程
		println!("v = {:?}", v);
	});

	handle.join().unwrap();
	// println!("{:?}", v); // ❌ 这里 v 已经被 move
}
```

这其实是 Rust 在“并发场景”里继续贯彻所有权模型：

- 线程之间默认不共享栈变量
- 需要共享时必须显式用 `Arc` 等结构，且要满足 `Send` / `Sync` 约束（后面详讲）

### 11.1.5 线程管理：`JoinHandle`、`Builder` 与 `thread::scope`

**JoinHandle**

- `join()`：等待线程结束并拿到返回值
- “不 join 也行”，但主线程结束后整个进程可能直接退出（导致子线程来不及完成）

**Builder：自定义线程**

```rust
use std::thread;

fn main() {
	let handle = thread::Builder::new()
		.name("worker-1".to_string())
		.spawn(|| {
			println!("hello from {:?}", thread::current().name());
		})
		.unwrap();

	handle.join().unwrap();
}
```

**thread::scope：借用数据的“作用域线程”**

如果你想让线程临时借用当前栈上的数据，而不是把所有权 move 进去，可以用 `thread::scope`（稳定版 Rust 已提供）。

```rust
use std::thread;

fn main() {
	let numbers = vec![1, 2, 3, 4, 5, 6];

	thread::scope(|s| {
		let mid = numbers.len() / 2;
		let (left, right) = numbers.split_at(mid);

		let h1 = s.spawn(|| left.iter().sum::<i32>());
		let h2 = s.spawn(|| right.iter().sum::<i32>());

		let sum = h1.join().unwrap() + h2.join().unwrap();
		println!("sum = {sum}");
	});
}
```

要点：

- `scope` 保证：所有在 scope 内创建的线程都会在 scope 结束前 join
- 因此允许线程借用非 `'static` 的引用

---

## 11.2 共享内存：`Mutex` 与 `RwLock`

“共享内存”路线的本质是：多个线程共享同一份数据，通过锁来保证同一时间只有安全的访问方式。

Rust 的常见组合拳：

- `Arc<T>`：线程安全的引用计数指针，用于“多线程共享所有权”
- `Mutex<T>`：互斥锁，一次只允许一个线程访问/修改 `T`
- `RwLock<T>`：读写锁，允许多个读者并发读，但写者需要独占

### 11.2.1 `Mutex<T>`：互斥访问

**最常见模式：`Arc<Mutex<T>>`**

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
	let counter = Arc::new(Mutex::new(0u64));
	let mut handles = vec![];

	for _ in 0..4 {
		let c = Arc::clone(&counter);
		handles.push(thread::spawn(move || {
			for _ in 0..1000 {
				let mut guard = c.lock().unwrap();
				*guard += 1;
				// guard 离开作用域时自动 unlock（RAII）
			}
		}));
	}

	for h in handles {
		h.join().unwrap();
	}

	println!("counter = {}", *counter.lock().unwrap());
}
```

几个关键点：

- `lock()` 返回 `MutexGuard<T>`，它实现了 `Deref/DerefMut`，像引用一样用
- `MutexGuard` drop 时自动释放锁（这也是 Rust 写锁很“难忘记 unlock”的原因）
- `lock().unwrap()`：如果其他线程在持锁时 panic，锁会进入“poisoned（中毒）”状态；`unwrap()` 会 panic

**锁中毒（poisoning）是什么**

锁中毒是一种“保守策略”：如果持锁期间发生 panic，那么共享数据可能处于不一致状态，后续再获取锁时就会得到一个 `PoisonError`。

你可以选择：

- 直接 `unwrap()`：把错误传播为 panic（很多示例/教学会这么写）
- 显式处理：比如继续拿到内部数据并做修复/丢弃

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
	let data = Arc::new(Mutex::new(vec![1, 2, 3]));
	let d1 = Arc::clone(&data);

	let _ = thread::spawn(move || {
		let _guard = d1.lock().unwrap();
		panic!("oops");
	}).join();

	match data.lock() {
		Ok(guard) => println!("ok: {:?}", *guard),
		Err(poisoned) => {
			let guard = poisoned.into_inner();
			println!("poisoned but recovered: {:?}", *guard);
		}
	}
}
```

**死锁（deadlock）**

Rust 的类型系统能消灭数据竞争，但不能“自动消灭死锁”。

常见死锁来源：

- 多把锁交叉获取，获取顺序不一致
- 持锁做了耗时操作（I/O、sleep、等待另一个锁/条件）

经验法则：

- 尽量缩短持锁时间（把耗时操作移出临界区）
- 多把锁统一约定获取顺序

### 11.2.2 `RwLock<T>`：多读单写

`RwLock` 适合“读多写少”的场景：

- 读锁：`read()`，可同时存在多个
- 写锁：`write()`，必须独占

```rust
use std::sync::{Arc, RwLock};
use std::thread;

fn main() {
	let config = Arc::new(RwLock::new(String::from("v1")));
	let mut handles = vec![];

	// 多个读者
	for _ in 0..3 {
		let c = Arc::clone(&config);
		handles.push(thread::spawn(move || {
			let v = c.read().unwrap();
			println!("read: {v}");
		}));
	}

	// 一个写者
	{
		let c = Arc::clone(&config);
		handles.push(thread::spawn(move || {
			let mut v = c.write().unwrap();
			*v = "v2".to_string();
			println!("write done");
		}));
	}

	for h in handles {
		h.join().unwrap();
	}
}
```

选择建议：

- 写频繁：优先 `Mutex`（读写锁在写多时可能更慢，且容易产生写者饥饿/读者饥饿，具体取决于实现与负载）
- 读远多于写：`RwLock` 更合适

---

## 11.3 消息传递：`Channel`（`std::sync::mpsc`）

消息传递（message passing）的思想是：**线程之间尽量不共享数据，而是把数据“发送过去”**。

Rust 标准库提供的 channel 在 `std::sync::mpsc`：

- `mpsc` = multiple producer, single consumer（多发送者，单接收者）
- `Sender<T>` 可以 clone（多个发送者）
- `Receiver<T>` 通常不 clone（单接收者）

### 11.3.1 基本用法：发送与接收

```rust
use std::sync::mpsc;
use std::thread;

fn main() {
	let (tx, rx) = mpsc::channel();

	thread::spawn(move || {
		tx.send(String::from("hello"))
			.expect("send failed");
	});

	let msg = rx.recv().expect("recv failed");
	println!("got: {msg}");
}
```

要点：

- `send(T)` 会把 `T` 的所有权移动进 channel
- `recv()` 会阻塞等待一条消息；若所有发送端都 drop，则返回 `Err`
- 非阻塞版本：`try_recv()`

### 11.3.2 多发送者：`Sender::clone`

```rust
use std::sync::mpsc;
use std::thread;

fn main() {
	let (tx, rx) = mpsc::channel();

	for id in 1..=3 {
		let tx = tx.clone();
		thread::spawn(move || {
			tx.send(format!("from worker {id}")).unwrap();
		});
	}

	drop(tx); // 关闭最后一个发送端，让下面的迭代能结束

	for msg in rx {
		println!("{msg}");
	}
}
```

这里 `for msg in rx` 的模式很常用：

- 接收端会持续迭代直到 channel 关闭（所有 `Sender` 都 drop）

### 11.3.3 有界 channel：`sync_channel`

默认 `channel()` 是“无界队列”（理论上可无限增长，实际受内存限制）。

如果你想要背压（backpressure），让发送者在队列满时阻塞，可以用 `sync_channel(capacity)`：

```rust
use std::sync::mpsc;
use std::thread;
use std::time::Duration;

fn main() {
	let (tx, rx) = mpsc::sync_channel(2);

	let producer = thread::spawn(move || {
		for i in 1..=5 {
			// 队列满时，这里会阻塞
			tx.send(i).unwrap();
			println!("sent {i}");
		}
	});

	let consumer = thread::spawn(move || {
		for v in rx {
			thread::sleep(Duration::from_millis(80));
			println!("recv {v}");
		}
	});

	producer.join().unwrap();
	consumer.join().unwrap();
}
```

选择建议：

- 需要控制内存、希望生产速度被消费速度约束：`sync_channel`
- 简单任务/小规模：`channel` 足够

---

## 11.4 `Send` 与 `Sync`：并发安全的“门槛”

如果说所有权/借用是 Rust 安全的地基，那么 `Send` / `Sync` 就是 Rust 并发安全的“门槛”。

它们都是 **marker trait（标记 trait）**，并且是 **auto trait（自动 trait）**：

- 绝大多数情况下你不需要手写 `impl Send for ...`，编译器会根据类型的字段自动推导
- 只有在极少数场景（尤其是涉及 `unsafe`）才需要手动实现

### 11.4.1 `Send` 是什么

`Send` 表示：

> 类型 `T` 的值可以安全地 **被移动到另一个线程**。

直观理解：如果一个类型不满足 `Send`，你就不能把它 move 进 `thread::spawn` 的闭包（也不能通过 channel 发送到另一线程）。

### 11.4.2 `Sync` 是什么

`Sync` 表示：

> 当 `T: Sync` 时，`&T` 可以安全地在多个线程之间共享。

更“硬核”的等价表述是：

> `T: Sync` 等价于 `&T: Send`

意思是：如果一个共享引用 `&T` 能被送到其他线程，那它就必须是“可并发共享”的。

### 11.4.3 哪些类型通常是 `Send` / `Sync`

一些经验结论（帮助你建立直觉）：

- 大部分“普通值类型”都是 `Send + Sync`
	- `i32` / `u64` / `bool` / `String` / `Vec<T>`（当 `T` 满足约束时）
- 裸指针 `*const T` / `*mut T` 的解引用是 `unsafe`；它们的 `Send/Sync` 能力也不应被当作“线程安全”的证明
- 单线程引用计数 `Rc<T>`：**不是 `Send` 也不是 `Sync`**
- 多线程引用计数 `Arc<T>`：
	- `Arc<T>: Send + Sync` 的前提是 `T: Send + Sync`（内部引用计数用原子操作实现）
- `RefCell<T>` / `Cell<T>`：通常 **不是 `Sync`**（它们的可变性并未做跨线程同步）
- `Mutex<T>` / `RwLock<T>`：
	- 它们本身提供跨线程同步；但内部 `T` 仍然会有约束（常见是 `T: Send`）

### 11.4.3.1 如何在编译期验证某类型是否 `Send/Sync`

当你不确定某个类型能不能跨线程时，一个很实用的技巧是写“断言函数”（只在编译期起作用）：

```rust
fn assert_send<T: Send>() {}
fn assert_sync<T: Sync>() {}

fn main() {
	assert_send::<i32>();
	assert_sync::<i32>();

	// 取消注释会编译失败：Rc 不是 Send/Sync
	// assert_send::<std::rc::Rc<i32>>();
	// assert_sync::<std::rc::Rc<i32>>();

	// 常见规则：Mutex<T> 通常要求 T: Send；Arc<T> 则往往要求 T: Send + Sync
	assert_send::<std::sync::Mutex<i32>>();
	assert_sync::<std::sync::Mutex<i32>>();
}
```

你可以用一个非常实用的“组合推导”来记：

- 如果一个类型内部包含了 `!Send` 的东西，那它通常也会是 `!Send`
- 如果一个类型内部包含了 `!Sync` 的东西，那它通常也会是 `!Sync`

这就是 auto trait 的“自动传播”。

### 11.4.4 例子：为什么 `Rc<RefCell<T>>` 不能跨线程

很多同学在单线程章节会写 `Rc<RefCell<T>>`，一到多线程就报错。

原因是：

- `Rc<T>` 的引用计数不是原子的，多线程同时增减会产生数据竞争
- `RefCell<T>` 的借用检查是运行时的，但没有跨线程同步语义

正确的多线程组合通常是：

- `Arc<Mutex<T>>`
- `Arc<RwLock<T>>`

示例：把 `Rc<RefCell<_>>` 改成 `Arc<Mutex<_>>`

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
	let shared = Arc::new(Mutex::new(vec![]));
	let mut handles = vec![];

	for i in 0..3 {
		let s = Arc::clone(&shared);
		handles.push(thread::spawn(move || {
			s.lock().unwrap().push(i);
		}));
	}

	for h in handles {
		h.join().unwrap();
	}

	println!("{:?}", shared.lock().unwrap());
}
```

### 11.4.5 边界条件：`Send/Sync` 只是“可跨线程”的必要条件

即使一个类型是 `Send + Sync`：

- 也不代表你的算法没有竞态（比如用 `AtomicUsize` 做计数，但你以为它保证了更复杂的不变量）
- 也不代表没有死锁（锁顺序问题仍然存在）

`Send/Sync` 解决的是“语言层面的未定义行为与数据竞争”，不是所有并发逻辑问题。

### 11.4.6 可以手动实现 `Send/Sync` 吗？

可以，但通常只在你封装了 `unsafe`，并且你能证明跨线程使用是安全时才这么做。

因为 `Send/Sync` 影响的是**跨线程的安全性承诺**，所以手动实现必须用 `unsafe impl`。

下面给一个“教学用”的示意：假设你封装了一个只读、永不释放、只会指向静态内存的指针句柄；你可能想让它能跨线程复制/移动。

```rust
#[derive(Copy, Clone)]
struct StaticPtr(*const u8);

// 只有当你能证明：跨线程读这个指针始终安全
unsafe impl Send for StaticPtr {}
unsafe impl Sync for StaticPtr {}

fn main() {
	static BYTES: [u8; 3] = [1, 2, 3];
	let p = StaticPtr(BYTES.as_ptr());

	// 这类类型通常配合更强的不变量/更完整封装使用
	let _ = p;
}
```

风险提示：

- **不要**为了“让代码编译通过”去乱加 `unsafe impl Send/Sync`
- 一旦承诺错了，多线程下会产生未定义行为（UB），bug 可能极难复现

实践建议：

- 优先用标准库提供的并发原语（`Arc/Mutex/RwLock/Atomic*`）
- 如果确实需要手写 `unsafe impl`，把不变量写进类型设计里，并尽可能把 `unsafe` 缩到最小

---

## 11.5 原子类型（Atomic Types）与使用场景

原子类型提供“无锁”的基础操作：在多线程下，对某个整数/指针/布尔进行读写与读改写（read-modify-write）时保证原子性。

标准库原子类型在 `std::sync::atomic`：

- `AtomicBool`
- `AtomicIsize` / `AtomicUsize`
- `AtomicI8/I16/I32/I64/I128`、`AtomicU8/...`（哪些可用取决于平台）
- `AtomicPtr<T>`

### 11.5.1 原子 vs 锁：怎么选

可以用一句话概括：

- 原子适合维护“很小的状态”（计数器、标志位、简单索引）
- 锁适合维护“复杂不变量”（结构体/集合的多字段一致性）

如果你需要“对多个字段同时保持一致”，原子很容易把程序带进微妙的竞态；此时用 `Mutex/RwLock` 往往更稳。

### 11.5.2 一个最常见场景：原子计数器

```rust
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use std::thread;

fn main() {
	let counter = Arc::new(AtomicUsize::new(0));
	let mut handles = vec![];

	for _ in 0..4 {
		let c = Arc::clone(&counter);
		handles.push(thread::spawn(move || {
			for _ in 0..1000 {
				c.fetch_add(1, Ordering::Relaxed);
			}
		}));
	}

	for h in handles {
		h.join().unwrap();
	}

	println!("counter = {}", counter.load(Ordering::Relaxed));
}
```

这个例子里使用 `Relaxed` 就足够，因为我们只关心“最终计数值”，不依赖计数器与其他数据之间的顺序关系。

### 11.5.3 原子内存序（Ordering）直觉

原子操作除了“原子性”，还涉及“可见性/重排序”——也就是内存序。

常用的 `Ordering`：

- `Relaxed`：只保证原子性，不提供跨线程的顺序/可见性约束
- `Release`：写入端发布（release）之前的写操作
- `Acquire`：读取端获取（acquire）之后的读操作
- `AcqRel`：读改写同时具备 acquire + release
- `SeqCst`：最强，提供全局一致的顺序（通常最慢、但最易推理）

一个典型的“发布-订阅”模式（单个标志位 + 数据）：

```rust
use std::sync::atomic::{AtomicBool, Ordering};
use std::hint;
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
	let ready = Arc::new(AtomicBool::new(false));
	let data = Arc::new(Mutex::new(None::<u32>));

	let ready_p = Arc::clone(&ready);
	let data_p = Arc::clone(&data);

	let producer = thread::spawn(move || {
		*data_p.lock().unwrap() = Some(99);
		ready_p.store(true, Ordering::Release);
	});

	let ready_c = Arc::clone(&ready);
	let data_c = Arc::clone(&data);

	let consumer = thread::spawn(move || {
		while !ready_c.load(Ordering::Acquire) {
			hint::spin_loop();
		}
		println!("data = {:?}", *data_c.lock().unwrap());
	});

	producer.join().unwrap();
	consumer.join().unwrap();
}
```

解释：

- 生产者先写数据，再用 `Release` 设置 `ready=true`
- 消费者用 `Acquire` 读取 `ready`，一旦看到 `true`，就能“同步看到”生产者在 release 之前的写入

注意：这个例子为了教学直觉仍然用了 `Mutex` 来保护 `data` 本身。
纯原子地发布复杂数据结构需要更多技巧（例如指针、生命周期、内存回收策略等），不适合作为入门默认方案。

### 11.5.4 什么时候该用原子

常见合适场景：

- 统计：请求数、命中次数（counter）
- 状态位：是否需要停止（stop flag）、是否已初始化（once flag）
- 无锁队列/环形缓冲的索引（需要更强的并发设计能力）

不适合的场景：

- 需要对 `Vec/HashMap` 做插入删除并保持一致性
- 需要跨多个变量维持不变量（比如“余额不能为负”+“交易记录一致”）

---

## 小结

- 线程 API：`thread::spawn` + `JoinHandle::join`，需要关注所有权与 `'static` 限制
- 共享内存：`Arc<Mutex<T>>` / `Arc<RwLock<T>>` 是最常用的安全共享方式；注意锁中毒与死锁
- 消息传递：`std::sync::mpsc` channel 让你用“传值”方式组织并发；`sync_channel` 能提供背压
- `Send/Sync`：Rust 并发安全的关键门槛，是 auto trait；不要轻易手写 `unsafe impl`
- 原子类型：适合小状态与计数器；内存序越强越易推理但可能更慢
